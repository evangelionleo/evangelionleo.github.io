---
date: 2020-04-12 17:15:49
layout: post
title: "Dependency Parser研究进展及主流方法"
subtitle:
description:
image: /assets/74651256.jpg
optimized_image: /assets/74651256.jpg
category:
tags:
-
author: Ayerlans
paginate: false
---
##### 引言:这两句话,放到现在的语义自动匹配模型里，几乎相同，但为什么到人类理解这里，这两句话就是完全不同的意思呢？![Snipaste_2020-04-13_01-23-42](/assets/Snipaste_2020-04-13_01-23-42.png)
**从语义角度来说，一句话的含义是有层次和主要元素的**
**主要元素用学术性的话语说就是语义框架，也就是我们所说的“主谓宾”。**(虽然不是所有的句子都会有主谓宾覆盖，但我们这里，先拿一个主谓宾的句子举个例子。)

**所以问题就来了，有没有一种结构化的表达方式，可以有效地解决语义表达这个问题？**
  这个问题其实有几大难点。首先，如果说存在这样一种结构，那么这个结构一定要具有普适性，其次，更难的问题是，如何让计算机实现把一个序列化的句子转化成这种结构。

接下来的部分，我们就来谈谈目前解决这两个问题的方法以及思考。自然语言理解主要有以下三种主流理论。

#### 补充 :语义表达&知识表达(有点啰嗦的补充知识)
1. Phrase structure（句法结构）：

- 图片解释:

  - 非终结符就是这张图里面，像“S、NP、VP”等这些没有实词的标签，在我们构成树状节点的结构中，它下面还会有子节点，有子节点的节点，我们都称之为非终结符。
  - 终结符就是这张图里面，像“she、bought、car”等这些具体的实词，是树状结构中的叶子节点。
  - 我们从句子层面看，一句话可以根据语义的层次性，即它们之间的紧密型，被表达成一个二叉树，如上图所示。
![Snipaste_2020-04-13_01-35-53](/assets/Snipaste_2020-04-13_01-35-53.png)

- 这套理论是由乔姆斯基提出的，在句法结构中，一个非终结符只能生成小于等于两个非终结符，或者生成一个终结符。

- 那这个句法结构有什么缺陷呢？我们看下图，首先它是一个强序列要求的结构。其次，它不是各种语言通用的框架，依赖于特定语言规则，普适性很差。最后，它反映的语义信息比较有限

2. Dependency structure（一层句法/依赖结构)：

它通过用词与词之间的有效边来表示语法关系，因此在形式上会更简单、直观。
- 见右图 ,左图还是Phrase structure
![Snipaste_2020-04-13_01-40-46](/assets/Snipaste_2020-04-13_01-40-46.png)
- 在上图这个例子里面，我们可以看到一条边SBJ，也就是指句子的主语，OBJ就是指句子的宾语，NMOD就是指名词的修饰词，它通过边的类型来定义词与词之间的关系。而边的类型比较多，目前有三十几种。


3. Frame semantics（框架语义）：


![Snipaste_2020-04-13_01-43-22](/assets/Snipaste_2020-04-13_01-43-22.png)
  它相比于之前的两个理论，更偏重于语义及知识表达，这套理论认为一个完整的表达是要结合背景知识的。
  比如“吃”这个词，不能独立于知识来讨论这个词应该怎么用，而要把它放在完整的语义结构中。“转”这个词也是如此。


#### Dependency parser
 Dependency parser的意义
其实要讨论dependency parser的意义，这可能是个比较难的话题，因为它是自然语言处理领域里面一项比较基础的研究，但它真正在实际应用中的效果，主要有以下几方面：
![Snipaste_2020-04-13_01-49-33](/assets/Snipaste_2020-04-13_01-49-33.png)

Tree-LSTM较Bi-LSTM并没有很明显的优势，所以“结构化是不是有必要”，仍然是一个争议点，在胡翔老师看来，他认为这个话题对dependency parser的研究相当于是对语言本质的一些揭露，它的研究成果对理解自然语言很有帮助，虽然它不一定在实际应用中起到效果。
###### Dependency Parsing
**句子的依赖结构表现在哪些单词依赖哪些单词。单词之间的这种关系及可以表示为优先级之间的关系等。**
通常情况下，对于一个输入句子：
$$
S=w0w1…wn
$$
我们用 w0 来表示 ROOT，我们将这个句子转换成一个图 G。

依赖性解析通常分为训练与预测两步：

  - 使用已经解析的注释库训练模型 M
  - 得到模型 M之后，对于句子 S，通过模型解析出图 G。


1. 基于转换的依赖性解析

  该方法就是通过训练数据训练一个状态机，通过状态机转换对源语句进行解析。

  基于贪心确定性过渡的解析#

  这个转换的系统本质也是一个状态机，但是不同的是，对于一个初始状态，会有多个终止状态。

  对于每一个源语句 
$$
S=w0w1…wn
$$
  每个状态可以表示成三部分
$$
c=(σ,β,A)
$$
  第一部分 σ用来存储来自 S 的 wi，使用栈存储
  β表示一个来自 S 的缓冲
  A 表示 (wi,r,wj)的集合，其中 wi,wj 来自 S，然后 r 表示 wi,wj之间的关系。
